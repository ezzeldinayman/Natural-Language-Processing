{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLzPrsY0zEqVASrv7m/7H8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHR8cTzRdPy-",
        "outputId": "d14b28ff-175b-4026-f5d0-37bd38febf16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  17.4M      0  0:00:04  0:00:04 --:--:-- 17.7M\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "DATA_PATH=Path('./dat/')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "#if not os.path.exists('./dat/aclImdb_v1.tar.gz'):\n",
        "if not os.path.exists('./dat/aclImdb'):\n",
        "    !curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "    !tar -xf aclImdb_v1.tar.gz -C {DATA_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "CLASSES = ['neg', 'pos']#, 'unsup']\n",
        "PATH=Path('./dat/aclImdb/')\n",
        "\n",
        "def get_texts(path):\n",
        "    texts,labels = [],[]\n",
        "    for idx,label in enumerate(CLASSES):\n",
        "        for fname in (path/label).glob('*.*'):\n",
        "            #texts.append(fixup(fname.open('r', encoding='utf-8').read()))\n",
        "            texts.append(fname.open('r', encoding='utf-8').read())\n",
        "            labels.append(idx)\n",
        "    #return np.array(texts),np.array(labels)\n",
        "    return texts, labels"
      ],
      "metadata": {
        "id": "SgCfJTmEdaFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_texts,trn_labels = get_texts(PATH/'train')\n",
        "tst_texts,tst_labels = get_texts(PATH/'test')"
      ],
      "metadata": {
        "id": "TqYXDh4bdiYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in trn_texts[:5]:\n",
        "  print(t)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4oRuHEDdlzw",
        "outputId": "3f574571-8bae-4a8b-9da3-e8cd352c44f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The House of the Dead was the worst movie I have ever seen, between the pathetic 'matrix' 360 camera angle attemps and the cheesy acting I fell asleep. I don't think that the director and set manager could decide whether it was raining or not, because there would be rain on one side of the boat and not the other. I would rate this movie a 1 out of 10, (10 being the best, 1 being the worst). Also jumping scenes from the movie to the game was really annoying, it makes you wonder if they were just making up for lose time. I beg anyone who reads this, NOT TO SEE IT. It's not worth the time.\n",
            "\n",
            "\n",
            "I've seen this movie today for the first time and I never heard of it before, probably because of it's poor message. <br /><br />First of all, the directing itself is quite good, the actors played well and the CGI (I'm not a fan of CGI) is magnificent. But that alone doesn't make a movie. No story at all, no message behind beautiful exploited talents.<br /><br />Or do I have to make people remember, the art of a director is not only your vision but to know how to tell a story. And this is what's missing the whole 7 minutes.<br /><br />There for a simple 4 rating.\n",
            "\n",
            "\n",
            "This must be accompanied by a special rating and warning: NOT RECOMMENDED TO NORMAL PEOPLE.<br /><br />The obsession of Daneliuc with the most dirty body functions becomes here a real nightmare. Also, it's evident that the man is a misanthrope, he hates everybody - his country his people, his actors, his job. And this hatred makes him blind and he forgets anymore the profession he knew long ago.<br /><br />This so called \"film\" is just a hideous string of disgusting images, with no artistic value and no professionist knowledge. It is an insult to good taste and to good sense. Shame, shame, shame!\n",
            "\n",
            "\n",
            "* Some spoilers *<br /><br />This movie is sometimes subtitled \"Life Everlasting.\" That's often taken as reference to the final scene, but more accurately describes how dead and buried this once-estimable series is after this sloppy and illogical send-off.<br /><br />There's a \"hey kids, let's put on a show air\" about this telemovie, which can be endearing in spots. Some fans will feel like insiders as they enjoy picking out all the various cameo appearances. Co-writer, co-producer Tom Fontana and his pals pack the goings-on with friends and favorites from other shows, as well as real Baltimore personages.<br /><br />That's on top of the returns of virtually all the members of the television's show varied casts, your old favorites as well as later non-favorites.<br /><br />There was always a tug-of-war pitting quality-conscious executive producer Barry Levinson, Fontana, James Yoshimura and the rest of the creative team against budget-conscious NBC execs, who simply wanted a another moronic police procedural like \"Nash Bridges,\" which regularly beat \"Homicide\" in the ratings. The pressure told as the show bounced between riveting realism that transcended its form, and sleazy sensationalism that demeaned it.<br /><br />Unfortunately for this movie, Fontana, co-writers Yoshimura and Eric Overmeyer and director Jean de Segonzac simply threw in the towel. They took the most ludicrous story are from the series, topped it with an unlikely and artistically unfruitful new plot line, and laid the burden of carrying the whole mess on one of the weaker cast members.<br /><br />Briefly, some time has passed since the last episode of the show. The former heart of Baltimore's homicide unit, Yaphet Kotto as Lt. Al Giardello, is now a Kurt Schmoke-like candidate for mayor, and Schmoke himself makes a cameo appearance. But this promising start immediately and improbably takes a tragic turn.<br /><br />The spotlight shifts to Giancarlo Esposito as Giardello's son Mike. A handsome man who has done good work elsewhere, Esposito was one of the pretty faces brought in late to supposedly enliven the TV series. But the question for viewers always was: is Mike that uncomfortable as Gee's son, or is Esposito that uncomfortable in the role?<br /><br />To be fair, Esposito doesn't get a chance to play out the main story without interruption. That's because the writers choose this moment to revive another storyline that spat on the intelligence of the show's loyal voters.<br /><br />An apparent snuff streaming video was promoted, and then seemed to actually take place, on the Internet. After some red herrings, the detectives arrested a repellent suspect. But Zaljko Ivanek's harassed and overworked Deputy States Attorney forgot to file motions in time, and the suspect was released, only to be murdered later.<br /><br />Let's summarize: he forgot to file the paperwork because it wasn't the most sensational case of his career, because the mayor, the attorney general, the governor, the entire Maryland Legislature, the U.S. Attorney General, NBC, Court TV, the BBC, AP, Reuters, People, The Sun, the Washington Post, the New York Times, the LA Times, Time Magazine, The Times of London, The Economist, The Johannesburg Mail and Guardian, L'Osservatore Romano, Le Figaro, Paris Match, L'Equipe and Computer World weren't calling every 10 minutes to ask about the status of the case.<br /><br />Nevertheless, the old gang of detectives and associates flocks back to Baltimore to help out. There's quite an array of talent on display. Unfortunately, with the limited amount of dialogue to hand out, some of them are merely on display.<br /><br />Two of the strongest actors, Clark Johnson and Melissa Leo, are criminally underused, while time wasted on Jon Seda and Michael Michelle could be better spent on commercials. The writers do seem to satirize this, presenting Jason Priestley as the latest big-deal detective. On the other hand, they give easy-come, easy-go Michelle Forbes a very affecting scene.<br /><br />There's some other sly casting, with actual Lt. Gary D'Addario, the center of the book that gave rise to the show, playing another detective. Guests drop in from other shows, like Whitney Allen doing her deadpan and clueless \"Miss Sally\" from the children's show beloved by the inmates on Fontana's \"Oz.\" Dina Napoli of WBAL TV turns up as herself. <br /><br />Even when entertaining, though, these guests can be distracting. Ed Begley Jr. actually advances the story in his brief appearance, playing Dr. Victor Ehrlich from Fontana's \"St. Elsewhere.\" He's still a vivid character, and fits in a hospital setting. Then you remember, didn't St. Elegius turn out to be an autistic boy's fantasy?<br /><br />The most useful cameo reflects corporate synergy. This movie was made when Court TV bought re-run rights to the series. That network contributed legal waif Helen Lucaitis, who had interviewed the Homicide team and later appeared on \"Oz.\" The TV correspondent does an efficient job summarizing the news, that is, plot points for latecomers.<br /><br />Although she's so thin that she disappears when she turns sideways, Lucaitis also adeptly handles a bit of physical comedy with Esposito. He shows more juice in his scenes with Lucaitis than with any of his usual colleagues. Perhaps those two should have done a spin-off.<br /><br />As the movie winds down, the cream of the cast rises to the top. Although they are saddled with a loser script, Andre Braugher and Kyle Secor overcome it. Their performances remind viewers what made Homicide, for considerable stretches, the best show on the air and one of the best television productions ever.<br /><br />It's fun to watch top pros do their stuff; it's just a shame this movie doesn't give them more of a chance. Die-hard fans may want to see this movie anyway, but you can live without it.\n",
            "\n",
            "\n",
            "Hubert Selby Jr. gave us the book \"Requiem For A Dream\" and co-wrote the screenplay to Aronofsky's movie of it. That movie succeeded on every level by delivering an intimate, and unbiased portrait of the horrors of the characters lives and the vices that destroyed them. \"Last Exit To Brooklyn\" still has the vice and the multiple characters living sad lives, but it hardly does them the same justice Aronofsky did.<br /><br />The film seems laughably anti-gay at times. Especially when in the film homosexuality equals death. One gay character gets stoned, is launched skyward by a speeding car, and lands dead on the pavement. Another is crucified and still more are simply beat up. Another exaggerated piece of shock value, that might actually have been compelling if it were done well, are scenes of the union workers literally doing battle with the strike-breakers. Who'd have thought a drama about Brooklyners would feature action sequences and truck explosions?<br /><br />The director, Uli Edel has a skill level like that of a TV director, but he is far below the cut for real movies. The film is clunky that can't even seem to settle on a genre. Lake is given a useless role that any mannequin could have filled and Baldwin only seems to know how to look stupid in his equally meager part. And then comes Jennifer Jason Leigh as our lead, a loathsome hooker named Tralala (believe it or not, I'm not joking). Her performance is nothing great and the fate of her character is dirty to say the least. Poor use of color and composition make it look cheaper than it is, and also takes the \"real\" edge off the more provocative bits. A failure.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvRNhvZTd1eQ",
        "outputId": "f1ae49f9-b974-4174-d5fa-0e25d3276ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"Hello-World. There's a robot strolling among us\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w817whhJeGH_",
        "outputId": "18350f53-f5b5-4b16-f21d-7e49a3acea54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello-World', '.', 'There', \"'s\", 'a', 'robot', 'strolling', 'among', 'us']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNK0LzWOhM0F",
        "outputId": "85e0563c-be36-4f31-d2b7-c19a8c59776a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test cleaning pipeline\n",
        "\n",
        "\n",
        "def rm_special_chars(text):\n",
        "  re1 = re.compile(r'  +')\n",
        "  x1 = text.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
        "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
        "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
        "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
        "  return re1.sub(' ', html.unescape(x1))\n",
        "\n",
        "\n",
        "def rm_non_ascii(text):\n",
        "  return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "def to_lower(text):\n",
        "  return text.lower()\n",
        "\n",
        "def rm_punctuation(text):\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return text.translate(translator)\n",
        "\n",
        "def rm_whitespaces(text):\n",
        "  return text.strip()\n",
        "\n",
        "def replace_numbers(text):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "def rm_stopwords(words, stop_words):\n",
        "  return [word for word in words if word not in stop_words]\n",
        "\n",
        "def stem_words(words):\n",
        "  stemmer = PorterStemmer()\n",
        "  return [stemmer.stem(word) for word in words]\n",
        "\n",
        "def lemmatize_words(words):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  return [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  return ' '.join([lemmatizer.lemmatize(word, pos='v') for word in words])\n",
        "\n",
        "def text2words(text):\n",
        "  return word_tokenize(text)"
      ],
      "metadata": {
        "id": "f54eq5FZeXN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "  text = rm_special_chars(text)\n",
        "  text = rm_non_ascii(text)\n",
        "  text = rm_punctuation(text)\n",
        "  text = to_lower(text)\n",
        "  text = replace_numbers(text)\n",
        "  words = text2words(text)\n",
        "  words = rm_stopwords(words, stop_words)\n",
        "  words = lemmatize_words(words)\n",
        "  words = lemmatize_verbs(words)\n",
        "\n",
        "  return words.split(' ')"
      ],
      "metadata": {
        "id": "1kyNqgx7iD46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_text(\"The cat sat on the mat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuVe1mBRjFbA",
        "outputId": "288b9c00-ef47-4382-fa67-a1da0b43a0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat', 'sit', 'mat']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_corpus(corpus):\n",
        "  return [normalize_text(t) for t in corpus]"
      ],
      "metadata": {
        "id": "ZruUGUJjjJXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_texts = normalize_corpus(trn_texts)\n",
        "tst_texts = normalize_corpus(tst_texts)"
      ],
      "metadata": {
        "id": "DFmRIrYLk_z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn = enumerate(trn_texts)\n",
        "next(trn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3p24MillOnb",
        "outputId": "8736aded-e318-444c-fb43-78b4f0ed8a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              " ['house',\n",
              "  'dead',\n",
              "  'worst',\n",
              "  'movie',\n",
              "  'ever',\n",
              "  'see',\n",
              "  'pathetic',\n",
              "  'matrix',\n",
              "  'camera',\n",
              "  'angle',\n",
              "  'attemps',\n",
              "  'cheesy',\n",
              "  'act',\n",
              "  'fell',\n",
              "  'asleep',\n",
              "  'dont',\n",
              "  'think',\n",
              "  'director',\n",
              "  'set',\n",
              "  'manager',\n",
              "  'could',\n",
              "  'decide',\n",
              "  'whether',\n",
              "  'rain',\n",
              "  'would',\n",
              "  'rain',\n",
              "  'one',\n",
              "  'side',\n",
              "  'boat',\n",
              "  'would',\n",
              "  'rate',\n",
              "  'movie',\n",
              "  'best',\n",
              "  'worst',\n",
              "  'also',\n",
              "  'jump',\n",
              "  'scene',\n",
              "  'movie',\n",
              "  'game',\n",
              "  'really',\n",
              "  'annoy',\n",
              "  'make',\n",
              "  'wonder',\n",
              "  'make',\n",
              "  'lose',\n",
              "  'time',\n",
              "  'beg',\n",
              "  'anyone',\n",
              "  'read',\n",
              "  'see',\n",
              "  'worth',\n",
              "  'time'])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim as gs"
      ],
      "metadata": {
        "id": "x7D1Ks9ow_Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gs.models.Word2Vec(\n",
        "    window = 10, #hyperparameter\n",
        "    min_count = 2, #at least 2 words must be present in the sentence in order to be considered\n",
        "    workers = 4 #4 threads\n",
        ")"
      ],
      "metadata": {
        "id": "GynGXPFWyQ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(trn_texts, progress_per = 1000)"
      ],
      "metadata": {
        "id": "kin3Rcsty3nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH022JBkzPLs",
        "outputId": "49b00266-ca6e-4d51-c2a1-c8e9d02578de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vGxvaKXzd7k",
        "outputId": "294102da-8ba4-495e-8ef4-90de98fcd2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(trn_texts, total_examples = model.corpus_count, epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_K8uoOBzVtV",
        "outputId": "8fc4077e-6fdb-417a-c186-4e3bdc21d7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13796126, 14983570)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"./myModelW2V.model\")"
      ],
      "metadata": {
        "id": "ZP2z7opkz_r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBbg-83A0Rsp",
        "outputId": "64d5a6a6-e3d4-4415-ac93-044a32f8efc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('decent', 0.744032621383667),\n",
              " ('great', 0.6992390155792236),\n",
              " ('bad', 0.6761851906776428),\n",
              " ('nice', 0.6680027842521667),\n",
              " ('alright', 0.6470168232917786),\n",
              " ('halfbad', 0.6350579857826233),\n",
              " ('excellent', 0.6117453575134277),\n",
              " ('fine', 0.6012598276138306),\n",
              " ('cool', 0.6008945107460022),\n",
              " ('okay', 0.5901791453361511)]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(\"good\", \"decent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVGbtaeD0YdB",
        "outputId": "0968112b-338b-4035-9cfc-481f71a4c9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7440326"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.get_vector(\"good\").size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306-Gld0-1Za",
        "outputId": "30823f37-12db-4748-926d-1715d4b7fcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRLGTc5t_Yhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}